{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing libs...\n",
      "setting up parser\n",
      "parsing args\n",
      "0: pt_fit_ss_fitbit_restingheartrate_mean\n",
      "1: pt_fit_ss_fitbit_restingheartrate_var\n",
      "2: pt_fit_ss_total_ave_met_mean\n",
      "3: pt_fit_ss_total_ave_met_var\n",
      "4: pt_fit_ss_total_fairly_active_min_mean\n",
      "5: pt_fit_ss_total_fairly_active_min_var\n",
      "6: pt_fit_ss_total_light_active_min_mean\n",
      "7: pt_fit_ss_total_light_active_min_var\n",
      "8: pt_fit_ss_total_sedentary_min_mean\n",
      "9: pt_fit_ss_total_sedentary_min_var\n",
      "10: pt_fit_ss_total_step_mean\n",
      "11: pt_fit_ss_total_step_var\n",
      "12: pt_fit_ss_total_very_active_min_mean\n",
      "13: pt_fit_ss_total_very_active_min_var\n",
      "14: pt_fit_ss_weekday_mean\n",
      "15: pt_fit_ss_weekday_var\n",
      "16: pt_fit_ss_weekend_ind_mean\n",
      "17: sex\n",
      "18: interview_age\n",
      "0: cbcl_scr_syn_anxdep_t\n",
      "1: cbcl_scr_syn_withdep_t\n",
      "2: cbcl_scr_syn_somatic_t\n",
      "3: cbcl_scr_syn_social_t\n",
      "4: cbcl_scr_syn_thought_t\n",
      "5: cbcl_scr_syn_attention_t\n",
      "6: cbcl_scr_syn_rulebreak_t\n",
      "7: cbcl_scr_syn_aggressive_t\n"
     ]
    }
   ],
   "source": [
    "#!/users/jflournoy/.conda/envs/abcd_ml_3.7/bin/python\n",
    "print('importing libs...')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import argparse\n",
    "from joblib import dump\n",
    "import logging\n",
    "\n",
    "print('setting up parser')\n",
    "# Models: Age + Sex in all\n",
    "#   *Day level: 1-7, 1-14, 1-21\n",
    "#   *Week level: 1, 1-2, 1-3\n",
    "#   *Summary\n",
    "#   Time-since CBCL interaction \n",
    "#   Fitbit variables: Most common versus everything\n",
    "#     Step count, HR (resting), Sleep duration\n",
    "#   Physical activity versus PA + Sleep in the subsample with sleep\n",
    "#     Compare this to full sample with sleep data imputed.\n",
    "#   Benchmarking\n",
    "#     Demographics (see variables sheet)\n",
    "#       interview_age\n",
    "#       Sex\n",
    "#       demo_race\n",
    "#     Fitbit minimal: Age + Sex\n",
    "#     Parental history?\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run some ML models on ABCD fitbit data')\n",
    "parser.add_argument('-p', '--predictorset', metavar='pset', type=str, \n",
    "                    help='A string specifying which predictor set to use. See code for specifics. \\\n",
    "                    Some sets require you to also specify the summary level (-s) and a time subset (-t).')\n",
    "parser.add_argument('-s', '--summary', metavar='level', type=str, \n",
    "                    help='A string specifying which level, [daily|weekly|id], of summary to use.')\n",
    "parser.add_argument('-t', '--time', metavar='max_time', type=int, \n",
    "                    help='An integer specifying the maximum time, either days, or weeks, you want to use. \\\n",
    "                    -t 7 would specify 7 days if this was a day-data model. Should be 7, 14, or 21 for \\\n",
    "                    days, or 1, 2, or 3 for weeks.')\n",
    "parser.add_argument('-y', '--outcome', metavar='outcome', type=str,\n",
    "                   help='A string specifying the outcome level: [subscale|scale|overall].')\n",
    "parser.add_argument('-ni', '--n_inner', metavar='N', type=int,\n",
    "                   help='Number of splits for inner-loop CV.')\n",
    "parser.add_argument('-no', '--n_outer', metavar='N', type=int,\n",
    "                   help='Number of splits for outer-loop CV.')\n",
    "parser.add_argument('-c', '--cores', metavar='Cores', type=int,\n",
    "                   help='Number of cores available.')\n",
    "parser.add_argument('--slurmid', metavar='ID', type=str,\n",
    "                   help='Slurm id, for logging.')\n",
    "\n",
    "print('parsing args')\n",
    "args = parser.parse_args(['-p', 'pa', '-s', 'id', '-t', '0', '-y', 'subscale', '-ni', '2', '-no', '2', '-c' , '1'])\n",
    "#args = parser.parse_args()\n",
    "\n",
    "logging.basicConfig(filename='log/abcd-ml_{}.log'.format(args.slurmid), level=logging.DEBUG)\n",
    "\n",
    "logging.info(args)\n",
    "\n",
    "logging.info('reading data')\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_data['sex'] = train_data['sex'].astype('category').cat.codes\n",
    "# y is 6-13, or 14-15, or 16\n",
    "#  PA daily: 20-46\n",
    "#  PA weekly: 47-64\n",
    "#  PA summary: 65-82\n",
    "#\n",
    "#  sleep daily: 84-125\n",
    "#  sleep weekly: 126-153\n",
    "#  sleep summary: 154-181\n",
    "#  Group index: 182\n",
    "# for thing in zip(range(len(train_data.columns)), train_data.columns):\n",
    "#     print(str(thing[0]) + ': ' + thing[1])\n",
    "\n",
    "pvarranges = {\"pa\" : {\"daily\" : range(20,47),\n",
    "                     \"weekly\" : range(47,65),\n",
    "                     \"id\" : range(65,82)},\n",
    "             \"sleep\" : {\"daily\" : range(84,126),\n",
    "                        \"weekly\" : range(126,154),\n",
    "                        \"id\" : range(154,181)}\n",
    "             }\n",
    "yvarranges = {\"subscale\" : range(6, 14),\n",
    "              \"scale\" : range(14,16),\n",
    "              \"overall\" : 16}\n",
    "\n",
    "### problem when pocolrange is a single column, list()ing it doesn't make a list\n",
    "### Sex column is not numeric.\n",
    "\n",
    "pcolrange = pvarranges[args.predictorset][args.summary]\n",
    "ycolrange = yvarranges[args.outcome]\n",
    "pcolnames = list(train_data.columns[pcolrange]) + ['sex', 'interview_age']\n",
    "if type(ycolrange) is int:\n",
    "    ycolnames = [train_data.columns[ycolrange]]\n",
    "else:\n",
    "    ycolnames = list(train_data.columns[ycolrange])\n",
    "\n",
    "for thing in zip(range(len(pcolnames)), list(pcolnames)):\n",
    "    print(str(thing[0]) + ': ' + thing[1])\n",
    "for thing in zip(range(len(ycolnames)), list(ycolnames)):\n",
    "    print(str(thing[0]) + ': ' + thing[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pt_fit_ss_fitbit_restingheartrate_mean',\n",
       " 'pt_fit_ss_fitbit_restingheartrate_var',\n",
       " 'pt_fit_ss_total_ave_met_mean',\n",
       " 'pt_fit_ss_total_ave_met_var',\n",
       " 'pt_fit_ss_total_fairly_active_min_mean',\n",
       " 'pt_fit_ss_total_fairly_active_min_var',\n",
       " 'pt_fit_ss_total_light_active_min_mean',\n",
       " 'pt_fit_ss_total_light_active_min_var',\n",
       " 'pt_fit_ss_total_sedentary_min_mean',\n",
       " 'pt_fit_ss_total_sedentary_min_var',\n",
       " 'pt_fit_ss_total_step_mean',\n",
       " 'pt_fit_ss_total_step_var',\n",
       " 'pt_fit_ss_total_very_active_min_mean',\n",
       " 'pt_fit_ss_total_very_active_min_var',\n",
       " 'pt_fit_ss_weekday_mean',\n",
       " 'pt_fit_ss_weekday_var',\n",
       " 'pt_fit_ss_weekend_ind_mean',\n",
       " 'sex',\n",
       " 'interview_age']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcolnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.predictorset in [\"pa\", \"sleep\"]:\n",
    "    if args.summary in [\"daily\", \"weekly\"]:\n",
    "        timecol = \"daynum\" if args.summary == \"daily\" else \"weekno\"\n",
    "        timerange = range(0, args.time)\n",
    "        timeindex = train_data[timecol].isin(timerange)\n",
    "        these_train_data = train_data[pcolnames + ycolnames + [timecol, 'idnum']][timeindex].drop_duplicates()\n",
    "        model_suffix=\"_{}_{}\".format(args.summary, args.time)\n",
    "        logging.info('Time column is {}, and time range is {}'.format(timecol, list(timerange)))\n",
    "    elif args.summary is \"id\":\n",
    "        these_train_data = train_data[pcolnames + ycolnames + ['idnum']].drop_duplicates()\n",
    "        model_suffix=\"_{}\".format(args.summary)\n",
    "    X = these_train_data[pcolnames].to_numpy()\n",
    "    Y = these_train_data[ycolnames].to_numpy()\n",
    "    groups = these_train_data['idnum'].to_numpy()\n",
    "else:\n",
    "    logging.error(\"Other models not yet specified.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62., 69., 59., ..., 73., 54., 63.],\n",
       "       [62., 54., 50., ..., 50., 51., 50.],\n",
       "       [50., 50., 54., ..., 50., 50., 50.],\n",
       "       ...,\n",
       "       [62., 68., 53., ..., 53., 50., 52.],\n",
       "       [60., 66., 66., ..., 59., 68., 73.],\n",
       "       [50., 54., 74., ..., 71., 50., 55.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing libs...\n",
      "setting up parser\n",
      "parsing args\n",
      "0: pt_fit_ss_fitbit_restingheartrate_mean\n",
      "1: pt_fit_ss_fitbit_restingheartrate_var\n",
      "2: pt_fit_ss_total_ave_met_mean\n",
      "3: pt_fit_ss_total_ave_met_var\n",
      "4: pt_fit_ss_total_fairly_active_min_mean\n",
      "5: pt_fit_ss_total_fairly_active_min_var\n",
      "6: pt_fit_ss_total_light_active_min_mean\n",
      "7: pt_fit_ss_total_light_active_min_var\n",
      "8: pt_fit_ss_total_sedentary_min_mean\n",
      "9: pt_fit_ss_total_sedentary_min_var\n",
      "10: pt_fit_ss_total_step_mean\n",
      "11: pt_fit_ss_total_step_var\n",
      "12: pt_fit_ss_total_very_active_min_mean\n",
      "13: pt_fit_ss_total_very_active_min_var\n",
      "14: pt_fit_ss_weekday_mean\n",
      "15: pt_fit_ss_weekday_var\n",
      "16: pt_fit_ss_weekend_ind_mean\n",
      "17: sex\n",
      "18: interview_age\n",
      "0: cbcl_scr_syn_totprob_t\n"
     ]
    }
   ],
   "source": [
    "outname=\"out/abcd-ml_{}{}\".format(args.predictorset, model_suffix)\n",
    "logging.info(\"outfile is {}\".format(outname))\n",
    "\n",
    "N_outer=args.n_outer\n",
    "N_inner=args.n_outer\n",
    "\n",
    "test_size=.2\n",
    "\n",
    "cvsplitter_outer = GroupShuffleSplit(n_splits=N_outer, test_size=test_size)\n",
    "cvsplitter_inner = GroupShuffleSplit(n_splits=N_inner, test_size=test_size) \n",
    "imputer = SimpleImputer(missing_values=np.nan, add_indicator=True)\n",
    "\n",
    "logging.info(\"Starting outer CV, N = {}\".format(N_outer))\n",
    "\n",
    "#Outer loop over N splits\n",
    "split_index = 0\n",
    "for train_idx, test_idx in cvsplitter_outer.split(X, Y, groups):\n",
    "    groups_train = groups[train_idx]\n",
    "    X_train = X[train_idx]\n",
    "    Y_train = Y[train_idx]\n",
    "\n",
    "    groups_test = groups[test_idx]\n",
    "    X_test = X[test_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "    \n",
    "    regressor=MultiTaskElasticNetCV(l1_ratio = [.1, .5, .7, .9, .95, .99, 1], \n",
    "                                    n_jobs = args.cores, \n",
    "                                    cv = list(cvsplitter_inner.split(X_train, Y_train, groups_train)))\n",
    "    estimator = make_pipeline(imputer, regressor)\n",
    "    logging.info(\"Training...\")\n",
    "    estimator.fit(X_train, Y_train)\n",
    "    \n",
    "    logging.info('Training: {:1.3} Testing: {:1.3}'.format(estimator.score(X_train, Y_train), estimator.score(X_test, Y_test)))\n",
    "    \n",
    "    out_dict={\"score_train\" : estimator.score(X_train, Y_train),\n",
    "              \"score_test\" : estimator.score(X_test, Y_test),\n",
    "              \"intercept\" : estimator.named_steps['multitaskelasticnetcv'].intercept_ ,\n",
    "              \"coef\" : estimator.named_steps['multitaskelasticnetcv'].coef_ ,\n",
    "              \"alpha\" : estimator.named_steps['multitaskelasticnetcv'].alpha_ ,\n",
    "              \"alphas\" : estimator.named_steps['multitaskelasticnetcv'].alphas_ ,\n",
    "              \"mse_path\" : estimator.named_steps['multitaskelasticnetcv'].mse_path_ ,\n",
    "              \"l1_ratio\" : estimator.named_steps['multitaskelasticnetcv'].l1_ratio_ ,\n",
    "              \"n_iter\" : estimator.named_steps['multitaskelasticnetcv'].n_iter_,\n",
    "              \"score_train\" : estimator.score(X_train, Y_train),\n",
    "              \"score_test\" : estimator.score(X_test, Y_test),\n",
    "              \"X_train\" : X_train,\n",
    "              \"Y_train\" : Y_train,\n",
    "              \"X_test\" : X_test,\n",
    "              \"Y_test\" : Y_test,\n",
    "              \"Y_pred_train\" : estimator.predict(X_train),\n",
    "              \"Y_pred_test\" : estimator.predict(X_test),\n",
    "              \"estimator\" : estimator}\n",
    "    logging.info(\"Pickling out_dict\")\n",
    "    dump(out_dict,'{}_s{:03}.pkl'.format(outname, split_index))\n",
    "    split_index += 1\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-abcd_ml_3.7]",
   "language": "python",
   "name": "conda-env-.conda-abcd_ml_3.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
