{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing libs...\n",
      "setting up parser\n",
      "parsing args\n"
     ]
    }
   ],
   "source": [
    "#!/users/jflournoy/.conda/envs/abcd_ml_3.7/bin/python\n",
    "print('importing libs...')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import argparse\n",
    "from joblib import dump\n",
    "import logging\n",
    "\n",
    "print('setting up parser')\n",
    "# Models: Age + Sex in all\n",
    "#   *Day level: 1-7, 1-14, 1-21\n",
    "#   *Week level: 1, 1-2, 1-3\n",
    "#   *Summary\n",
    "#   Time-since CBCL interaction \n",
    "#   Fitbit variables: Most common versus everything\n",
    "#     Step count, HR (resting), Sleep duration\n",
    "#   Physical activity versus PA + Sleep in the subsample with sleep\n",
    "#     Compare this to full sample with sleep data imputed.\n",
    "#   Benchmarking\n",
    "#     Demographics (see variables sheet)\n",
    "#       interview_age\n",
    "#       Sex\n",
    "#       demo_race\n",
    "#     Fitbit minimal: Age + Sex\n",
    "#     Parental history?\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run some ML models on ABCD fitbit data')\n",
    "parser.add_argument('-p', '--predictorset', metavar='pset', type=str, \n",
    "                    help='A string specifying which predictor set to use. See code for specifics. \\\n",
    "                    Some sets require you to also specify the summary level (-s) and a time subset (-t). \\\n",
    "                    Possible values are \"baseline\" (sex + age), \"fbmin\" (Fitbit minimal), \\\n",
    "                    \"pa\" (physical activity), \"sleep\" (sleep), \"pasleep\" (both pa and sleep in \\\n",
    "                    subsample with sleep data).')\n",
    "parser.add_argument('-s', '--summary', metavar='level', type=str, \n",
    "                    help='A string specifying which level, [daily|weekly|id], of summary to use.')\n",
    "parser.add_argument('-t', '--time', metavar='max_time', type=int, \n",
    "                    help='An integer specifying the maximum time, either days, or weeks, you want to use. \\\n",
    "                    -t 7 would specify 7 days if this was a day-data model. Should be 7, 14, or 21 for \\\n",
    "                    days, or 1, 2, or 3 for weeks.')\n",
    "parser.add_argument('-y', '--outcome', metavar='outcome', type=str,\n",
    "                   help='A string specifying the outcome level: [subscale|scale|overall].')\n",
    "parser.add_argument('-ni', '--n_inner', metavar='N', type=int,\n",
    "                   help='Number of splits for inner-loop CV.')\n",
    "parser.add_argument('-no', '--n_outer', metavar='N', type=int,\n",
    "                   help='Number of splits for outer-loop CV.')\n",
    "parser.add_argument('-c', '--cores', metavar='Cores', type=int,\n",
    "                   help='Number of cores available.')\n",
    "parser.add_argument('--slurmid', metavar='ID', type=str,\n",
    "                   help='Slurm id, for logging.')\n",
    "\n",
    "print('parsing args')\n",
    "args = parser.parse_args(['-p', 'fbmin', '-s', 'weekly', '-t', '2', '-y', 'overall', '-ni', '2', '-no', '2', '-c' , '1', '--slurmid', 'NADA'])\n",
    "#args = parser.parse_args()\n",
    "\n",
    "logging.basicConfig(filename='log/abcd-ml_{}.log'.format(args.slurmid), level=logging.DEBUG)\n",
    "\n",
    "logging.info(args)\n",
    "\n",
    "logging.info('reading data')\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_data['sex'] = train_data['sex'].astype('category').cat.codes\n",
    "# y is 6-13, or 14-15, or 16\n",
    "#  PA daily: 20-46\n",
    "#  PA weekly: 47-64\n",
    "#  PA summary: 65-82\n",
    "#\n",
    "#  sleep daily: 84-125\n",
    "#  sleep weekly: 126-153\n",
    "#  sleep summary: 154-181\n",
    "#  Group index: 182\n",
    "# for thing in zip(range(len(train_data.columns)), train_data.columns):\n",
    "#     print(str(thing[0]) + ': ' + thing[1])\n",
    "\n",
    "pvarranges = {\"fbmin\" : {    \"daily\"  : [20, 35, 114],\n",
    "                             \"weekly\" : [47, 57, 146],\n",
    "                             \"id\"     : [65, 75, 174]},\n",
    "              \"fbminpa\" : {  \"daily\"  : [20, 35],\n",
    "                             \"weekly\" : [47, 57],\n",
    "                             \"id\"     : [65, 75]},\n",
    "              \"pa\" :        {\"daily\"  : range(20,47),\n",
    "                             \"weekly\" : range(47,65),\n",
    "                             \"id\"     : range(65,82)},\n",
    "             \"sleep\" :      {\"daily\"  : range(84,126),\n",
    "                             \"weekly\" : range(126,154),\n",
    "                             \"id\"     : range(154,181)},\n",
    "             \"pasleep\" :    {\"daily\"  : list(range(20,47)) + list(range(84,126)),\n",
    "                             \"weekly\" : list(range(47,65)) + list(range(126,154)),\n",
    "                             \"id\"     : list(range(65,82)) + list(range(154,181))}\n",
    "             }\n",
    "yvarranges = {\"subscale\" : range(6, 14),\n",
    "              \"scale\" : range(14,16),\n",
    "              \"overall\" : 16}\n",
    "\n",
    "### problem when pocolrange is a single column, list()ing it doesn't make a list\n",
    "### Sex column is not numeric.\n",
    "baselinevars = ['sex', 'interview_age']\n",
    "\n",
    "if args.predictorset == \"baseline\":\n",
    "    pcolnames = baselinevars\n",
    "else:    \n",
    "    pcolrange = pvarranges[args.predictorset][args.summary]\n",
    "    pcolnames = list(train_data.columns[pcolrange]) + baselinevars\n",
    "\n",
    "ycolrange = yvarranges[args.outcome]\n",
    "if type(ycolrange) is int:\n",
    "    ycolnames = [train_data.columns[ycolrange]]\n",
    "else:\n",
    "    ycolnames = list(train_data.columns[ycolrange])\n",
    "\n",
    "for thing in zip(range(len(pcolnames)), list(pcolnames)):\n",
    "    logging.info(str(thing[0]) + ': ' + thing[1])\n",
    "for thing in zip(range(len(ycolnames)), list(ycolnames)):\n",
    "    logging.info(str(thing[0]) + ': ' + thing[1])\n",
    "\n",
    "logging.debug(\"args.summary is {} of type {} and truth value is {}\".format(args.summary, type(args.summary), args.summary == \"id\"))\n",
    "\n",
    "if args.predictorset in [\"sleep\", \"pasleep\", \"fbmin\"]:\n",
    "    selectrows = (train_data['has_sleep'] == 1) & (train_data['has_activity'] == 1)\n",
    "else:\n",
    "    selectrows = train_data['has_activity'] == 1\n",
    "\n",
    "if args.predictorset in [\"pa\", \"sleep\", \"pasleep\", \"fbmin\", \"fbminpa\"]:\n",
    "    if args.summary in [\"daily\", \"weekly\"]:\n",
    "        timecol = \"daynum\" if args.summary == \"daily\" else \"weekno\"\n",
    "        timerange = range(0, args.time)\n",
    "        selectrows = selectrows & train_data[timecol].isin(timerange) \n",
    "        these_train_data = train_data[pcolnames + ycolnames + [timecol, 'idnum']][selectrows].drop_duplicates()\n",
    "        model_suffix=\"_{}_{}\".format(args.summary, args.time)\n",
    "        logging.info('Time column is {}, and time range is {}'.format(timecol, list(timerange)))\n",
    "    elif args.summary == \"id\":\n",
    "        logging.debug(\"colnames to select are {}, {}, {}\".format(pcolnames, ycolnames, ['idnum']))\n",
    "        logging.debug(\"shape of selection will be {}.\".format(train_data[pcolnames + ycolnames + ['idnum']].drop_duplicates().shape))\n",
    "        these_train_data = train_data[pcolnames + ycolnames + ['idnum']][selectrows].drop_duplicates()\n",
    "        model_suffix=\"_{}\".format(args.summary)\n",
    "elif args.predictorset == \"baseline\":\n",
    "    these_train_data = train_data[baselinevars + ycolnames + ['idnum']][selectrows].drop_duplicates()\n",
    "else:\n",
    "    logging.error(\"Other models not yet specified.\")\n",
    "\n",
    "X = these_train_data[pcolnames].to_numpy()\n",
    "Y = these_train_data[ycolnames].to_numpy()\n",
    "groups = these_train_data['idnum'].to_numpy()\n",
    "    \n",
    "logging.debug(\"these_train_data shape is {}\".format(these_train_data.shape))    \n",
    "\n",
    "outname=\"out/abcd-ml_{}{}\".format(args.predictorset, model_suffix)\n",
    "logging.info(\"outfile is {}\".format(outname))\n",
    "\n",
    "N_outer=args.n_outer\n",
    "N_inner=args.n_outer\n",
    "\n",
    "test_size=.2\n",
    "\n",
    "cvsplitter_outer = GroupShuffleSplit(n_splits=N_outer, test_size=test_size)\n",
    "cvsplitter_inner = GroupShuffleSplit(n_splits=N_inner, test_size=test_size) \n",
    "imputer = SimpleImputer(missing_values=np.nan, add_indicator=True)\n",
    "\n",
    "logging.info(\"Starting outer CV, N = {}\".format(N_outer))\n",
    "\n",
    "#Outer loop over N splits\n",
    "split_index = 0\n",
    "for train_idx, test_idx in cvsplitter_outer.split(X, Y, groups):\n",
    "    groups_train = groups[train_idx]\n",
    "    X_train = X[train_idx]\n",
    "    Y_train = Y[train_idx]\n",
    "\n",
    "    groups_test = groups[test_idx]\n",
    "    X_test = X[test_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "    \n",
    "    regressor=MultiTaskElasticNetCV(l1_ratio = [.1, .5, .7, .9, .95, .99, 1], \n",
    "                                    n_jobs = args.cores, \n",
    "                                    cv = list(cvsplitter_inner.split(X_train, Y_train, groups_train)))\n",
    "    estimator = make_pipeline(imputer, regressor)\n",
    "    logging.info(\"Training...\")\n",
    "    estimator.fit(X_train, Y_train)\n",
    "    \n",
    "    logging.info('Training: {:1.3} Testing: {:1.3}'.format(estimator.score(X_train, Y_train), estimator.score(X_test, Y_test)))\n",
    "    \n",
    "    out_dict={\"score_train\" : estimator.score(X_train, Y_train),\n",
    "              \"score_test\" : estimator.score(X_test, Y_test),\n",
    "              \"intercept\" : estimator.named_steps['multitaskelasticnetcv'].intercept_ ,\n",
    "              \"coef\" : estimator.named_steps['multitaskelasticnetcv'].coef_ ,\n",
    "              \"alpha\" : estimator.named_steps['multitaskelasticnetcv'].alpha_ ,\n",
    "              \"alphas\" : estimator.named_steps['multitaskelasticnetcv'].alphas_ ,\n",
    "              \"mse_path\" : estimator.named_steps['multitaskelasticnetcv'].mse_path_ ,\n",
    "              \"l1_ratio\" : estimator.named_steps['multitaskelasticnetcv'].l1_ratio_ ,\n",
    "              \"n_iter\" : estimator.named_steps['multitaskelasticnetcv'].n_iter_,\n",
    "              \"score_train\" : estimator.score(X_train, Y_train),\n",
    "              \"score_test\" : estimator.score(X_test, Y_test),\n",
    "              \"xnames\" : pcolnames,\n",
    "              \"ynames\" : ycolnames,\n",
    "              \"X_train\" : X_train,\n",
    "              \"Y_train\" : Y_train,\n",
    "              \"X_test\" : X_test,\n",
    "              \"Y_test\" : Y_test,\n",
    "              \"Y_pred_train\" : estimator.predict(X_train),\n",
    "              \"Y_pred_test\" : estimator.predict(X_test),\n",
    "              \"estimator\" : estimator}\n",
    "    this_outname = '{}_s{:03}_{}.pkl'.format(outname, split_index, args.slurmid)\n",
    "    logging.info(\"Pickling out_dict to {}\".format(this_outname))\n",
    "    dump(out_dict,this_outname)\n",
    "    split_index += 1\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-abcd_ml_3.7]",
   "language": "python",
   "name": "conda-env-.conda-abcd_ml_3.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
